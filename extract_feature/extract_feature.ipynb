{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python   #python2 can run by terminal\n",
    "\n",
    "#change two position model input and result output\n",
    "#use caffe or caffe_net docker container more quickly\n",
    "#change input list file such as test1\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import glob\n",
    "import caffe\n",
    "import os\n",
    "\n",
    "\n",
    "# GLOBALS\n",
    "SET_MODE = 'gpu' # 'cpu' to use the cpu mode\n",
    "DEVICE_ID = 0 # Choose your gpu ID, if you are using gpu mode\n",
    "\n",
    "#PRETRAINED_FILE = 'path_to_one_of_our_caffe_models.caffemodel' # IMPORTANT: You need to select a pretrained model\n",
    "#Below you have an example for the Lq loss trained with dataset UCF101\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MODEL_FILE = 'path_to_the_correspoding_deploy.prototxt'  #IMPORTANT: You need to select the corresponding deploy.prototxt\n",
    "#Below you have an example for the Lq loss trained with dataset UCF101\n",
    "MODEL_FILE = '/opt/data/action_3/deploy_Lq_loss.prototxt'\n",
    "\n",
    "\n",
    "\n",
    "HEIGHT = 227\n",
    "WIDTH = 227\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    if SET_MODE == 'gpu':\n",
    "        caffe.set_mode_gpu()\n",
    "        caffe.set_device(DEVICE_ID)\n",
    "    elif SET_MODE == 'cpu':\n",
    "        caffe.set_mode_cpu()\n",
    "\n",
    "        \n",
    "    for model_use in range(2,6):\n",
    "\n",
    "\n",
    "        output_dir=\"result_\"+str(model_use)  \n",
    "        TEST_DATA_FILE = 'test'+str(model_use)+'.txt'  #from 1:5\n",
    "        PRETRAINED_FILE='/opt/data/action_3/model_'+str(model_use)+'/Lq_loss_iter_5000.caffemodel'  #change model_1/pretrain/....\n",
    "\n",
    "        #PRETRAINED_FILE='/opt/data/action_3/models_pretrained_UCF/UCF101/lq_loss/caffe_models/Lq_loss_iter_5000.caffemodel'  #pretrained UCF model\n",
    "\n",
    "        if(os.path.exists(output_dir)):\n",
    "            os.removedirs(output_dir)\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "        net = caffe.Net(MODEL_FILE, PRETRAINED_FILE, caffe.TEST)\n",
    "\n",
    "        # Make sure the video list file provided does not have a blank line at the end\n",
    "        with open(TEST_DATA_FILE, 'r') as f:\n",
    "            f_lines = f.readlines()\n",
    "\n",
    "        video_dict = {}\n",
    "        video_order = []\n",
    "\n",
    "        for ix, line in enumerate(f_lines):\n",
    "            clc_video = line.split(\"\\t\")[0].strip()\n",
    "            clc_video = clc_video.split('/')[1].strip()\n",
    "            frames = glob.glob('RGB_for_extract_feature/%s/*.jpg' %(clc_video))\n",
    "            num_frames = len(frames)\n",
    "            print num_frames\n",
    "            video_dict[clc_video] = {}\n",
    "            video_dict[clc_video]['frames'] = frames[0].split('/frame')[-2] + '/frame_%04d.jpg'\n",
    "            video_dict[clc_video]['reshape'] = (240, 320)\n",
    "            video_dict[clc_video]['num_frames'] = num_frames\n",
    "            video_order.append(clc_video)\n",
    "\n",
    "        video_dict = video_dict\n",
    "        num_videos = len(video_dict.keys())\n",
    "\n",
    "        # Set data transformer up\n",
    "        shape = (1, 3, HEIGHT, WIDTH)\n",
    "\n",
    "        transformer = caffe.io.Transformer({'data_in': shape})\n",
    "        transformer.set_raw_scale('data_in', 255)\n",
    "        image_mean = [103.939, 116.779, 128.68]\n",
    "\n",
    "        channel_mean = np.zeros((3,227,227))\n",
    "        for channel_index, mean_val in enumerate(image_mean):\n",
    "            channel_mean[channel_index, ...] = mean_val\n",
    "\n",
    "        transformer.set_mean('data_in', channel_mean)\n",
    "        transformer.set_channel_swap('data_in', (2, 1, 0))\n",
    "        transformer.set_transpose('data_in', (2, 0, 1))\n",
    "\n",
    "        idx_list = range(0, num_videos)\n",
    "        features = []\n",
    "        eval_frames =[]\n",
    "        for j in idx_list:\n",
    "            key = video_order[j]\n",
    "            video_reshape = video_dict[key]['reshape']\n",
    "            num_frames = video_dict[key]['num_frames']\n",
    "            frames = video_dict[key]['frames']\n",
    "            video_frames = []\n",
    "            video_feat = []\n",
    "\n",
    "            for i in range(0,num_frames): # range(np.round(num_frames/20)+1):  --> Analysis each 20 frames\n",
    "                idx = i + 1\n",
    "                if (idx > num_frames):\n",
    "                    idx = num_frames\n",
    "                curr_frame = frames % idx\n",
    "\n",
    "                data_in = caffe.io.load_image(curr_frame)\n",
    "\n",
    "                if (data_in.shape[0] < video_reshape[0]) | (data_in.shape[1] < video_reshape[0]):\n",
    "                    data_in = caffe.io.resize_image(data_in, video_reshape)\n",
    "\n",
    "                processed_image = transformer.preprocess('data_in',data_in)\n",
    "                processed_image = np.reshape(processed_image, (1,3,227,227))\n",
    "                out = net.forward_all(blobs=['fc7'],data=processed_image)\n",
    "\n",
    "                features.append(out['fc7'][0])\n",
    "                video_feat.append(out['fc7'][0])\n",
    "\n",
    "                video_frames.append(curr_frame)\n",
    "                eval_frames.append(curr_frame)\n",
    "\n",
    "                print \"Frame {}/{}, done\".format(idx, num_frames)\n",
    "\n",
    "            print \"Video {}: {}, done\".format(j, key)\n",
    "            video_feat = np.vstack(video_feat)\n",
    "            video_frames = np.hstack(video_frames)\n",
    "\n",
    "            res = dict()\n",
    "            res['feat'] = video_feat\n",
    "            res['frames'] = video_frames\n",
    "            sio.savemat(output_dir+'/{}'.format(key),res)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for model_use in range(2,6):\n",
    "    print(str(model_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
